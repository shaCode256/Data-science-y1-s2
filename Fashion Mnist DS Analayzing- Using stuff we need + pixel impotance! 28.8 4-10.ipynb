{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\97252\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\97252\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\97252\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\97252\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\97252\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\97252\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\97252\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\97252\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\97252\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\97252\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\97252\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\97252\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\97252\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\97252\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "> 90.883\n",
      "> 90.958\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b1567a72068d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;31m# entry point, run the test harness\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m \u001b[0mrun_test_harness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-b1567a72068d>\u001b[0m in \u001b[0;36mrun_test_harness\u001b[1;34m()\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprep_pixels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[1;31m# evaluate model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistories\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m         \u001b[1;31m# learning curves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0msummarize_diagnostics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistories\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-b1567a72068d>\u001b[0m in \u001b[0;36mevaluate_model\u001b[1;34m(dataX, dataY, n_folds)\u001b[0m\n\u001b[0;32m     61\u001b[0m                 \u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_ix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_ix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_ix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_ix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m                 \u001b[1;31m# fit model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m                 \u001b[1;31m# evaluate model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m                 \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# baseline cnn model for fashion mnist\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "\t# load dataset\n",
    "\t(trainX, trainY), (testX, testY) = fashion_mnist.load_data()\n",
    "\t# reshape dataset to have a single channel\n",
    "\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
    "\t# one hot encode target values\n",
    "\ttrainY = to_categorical(trainY)\n",
    "\ttestY = to_categorical(testY)\n",
    "\treturn trainX, trainY, testX, testY\n",
    "\n",
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "\t# convert from integers to floats\n",
    "\ttrain_norm = train.astype('float32')\n",
    "\ttest_norm = test.astype('float32')\n",
    "\t# normalize to range 0-1\n",
    "\ttrain_norm = train_norm / 255.0\n",
    "\ttest_norm = test_norm / 255.0\n",
    "\t# return normalized images\n",
    "\treturn train_norm, test_norm\n",
    "\n",
    "# define cnn model\n",
    "def define_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(10, activation='softmax'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.01, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "# evaluate a model using k-fold cross-validation\n",
    "def evaluate_model(dataX, dataY, n_folds=5):\n",
    "\tscores, histories = list(), list()\n",
    "\t# prepare cross validation\n",
    "\tkfold = KFold(n_folds, shuffle=True, random_state=1)\n",
    "\t# enumerate splits\n",
    "\tfor train_ix, test_ix in kfold.split(dataX):\n",
    "\t\t# define model\n",
    "\t\tmodel = define_model()\n",
    "\t\t# select rows for train and test\n",
    "\t\ttrainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\n",
    "\t\t# fit model\n",
    "\t\thistory = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=0)\n",
    "\t\t# evaluate model\n",
    "\t\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
    "\t\tprint('> %.3f' % (acc * 100.0))\n",
    "\t\t# append scores\n",
    "\t\tscores.append(acc)\n",
    "\t\thistories.append(history)\n",
    "\treturn scores, histories\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(histories):\n",
    "\tfor i in range(len(histories)):\n",
    "\t\t# plot loss\n",
    "\t\tpyplot.subplot(211)\n",
    "\t\tpyplot.title('Cross Entropy Loss')\n",
    "\t\tpyplot.plot(histories[i].history['loss'], color='blue', label='train')\n",
    "\t\tpyplot.plot(histories[i].history['val_loss'], color='orange', label='test')\n",
    "\t\t# plot accuracy\n",
    "\t\tpyplot.subplot(212)\n",
    "\t\tpyplot.title('Classification Accuracy')\n",
    "\t\tpyplot.plot(histories[i].history['accuracy'], color='blue', label='train')\n",
    "\t\tpyplot.plot(histories[i].history['val_accuracy'], color='orange', label='test')\n",
    "\tpyplot.show()\n",
    "\n",
    "# summarize model performance\n",
    "def summarize_performance(scores):\n",
    "\t# print summary\n",
    "\tprint('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores)))\n",
    "\t# box and whisker plots of results\n",
    "\tpyplot.boxplot(scores)\n",
    "\tpyplot.show()\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# prepare pixel data\n",
    "\ttrainX, testX = prep_pixels(trainX, testX)\n",
    "\t# evaluate model\n",
    "\tscores, histories = evaluate_model(trainX, trainY)\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(histories)\n",
    "\t# summarize estimated performance\n",
    "\tsummarize_performance(scores)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\97252\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\97252\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\97252\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\97252\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\97252\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\97252\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\97252\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\97252\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\97252\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\97252\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\97252\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\97252\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_prep = x_train / 255\n",
    "x_test_prep = x_test / 255\n",
    "\n",
    "x_train_prep_1d = x_train_prep.reshape(-1, 28 * 28)\n",
    "x_test_prep_1d = x_test_prep.reshape(-1, 28 * 28)\n",
    "\n",
    "x_train_prep_3d = x_train_prep.reshape(-1, 28, 28, 1)\n",
    "x_test_prep_3d = x_test_prep.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def find_example(model, x, y, true_class, predicted_class):\n",
    "    y_true = y\n",
    "    y_pred = model.predict(x)\n",
    "    found_index = None\n",
    "    for index, (current_y_true, current_y_pred) in enumerate(zip(y_true, y_pred)):\n",
    "        if current_y_true == true_class and current_y_pred == predicted_class:\n",
    "            found_index = index\n",
    "            break\n",
    "    return found_index\n",
    "\n",
    "def plot_example(model, x, y, true_class, predicted_class, value=None):\n",
    "    index = find_example(model, x, y, true_class, predicted_class)\n",
    "    print('True class:', classes[true_class])\n",
    "    print('Predicted class:', classes[predicted_class])\n",
    "    if value is not None:\n",
    "        print('Misclassified', value, 'times')\n",
    "    if index is not None:\n",
    "        plt.imshow(x_test_prep[index])\n",
    "        plt.show()\n",
    "    print('')\n",
    "\n",
    "target_names = ['0','1', '2', '3','4', '5','6','7','8','9']\n",
    "\n",
    "def analyze_model(model, x, y, inspect_n=10):\n",
    "    y_pred = model.predict(x)\n",
    "    print(classification_report(y, y_pred, target_names=target_names))\n",
    "    conf_matrix = confusion_matrix(y, y_pred)\n",
    "    print('Confusion matrix:')\n",
    "    print(conf_matrix)\n",
    "    print('')\n",
    "    for _ in range(10):\n",
    "        conf_matrix[_][_] = 0\n",
    "    conf_matrix_flat = conf_matrix.reshape(-1, 1)\n",
    "    biggest_indices = heapq.nlargest(inspect_n, range(len(conf_matrix_flat)), conf_matrix_flat.take)\n",
    "    biggest_indices = np.unravel_index(biggest_indices, conf_matrix.shape)\n",
    "    highest_values = conf_matrix[biggest_indices]  \n",
    "#    for x_index, y_index, value in zip(biggest_indices[0], biggest_indices[1], highest_values):\n",
    "#        plot_example(model, x, y, x_index, y_index, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5900666666666666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "naive_bayes = GaussianNB()\n",
    "print(np.mean(cross_val_score(estimator=naive_bayes, cv=4, scoring='accuracy', X=x_train_prep_1d, y=y_train)))\n",
    "naive_bayes.fit(x_train_prep_1d, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.59      0.68      1000\n",
      "           2       0.64      0.94      0.76      1000\n",
      "           3       0.59      0.32      0.42      1000\n",
      "           4       0.44      0.55      0.49      1000\n",
      "           5       0.38      0.78      0.51      1000\n",
      "           6       0.93      0.28      0.43      1000\n",
      "           7       0.32      0.04      0.07      1000\n",
      "           8       0.51      0.99      0.67      1000\n",
      "           9       0.83      0.71      0.77      1000\n",
      "          10       0.91      0.67      0.77      1000\n",
      "\n",
      "    accuracy                           0.59     10000\n",
      "   macro avg       0.64      0.59      0.56     10000\n",
      "weighted avg       0.64      0.59      0.56     10000\n",
      "\n",
      "Confusion matrix:\n",
      "[[586  64  29 162 110   0  20   0  29   0]\n",
      " [  1 939  14  36   7   0   1   0   2   0]\n",
      " [  7  14 324  65 545   0  23   0  22   0]\n",
      " [  9 387   6 545  43   0   4   0   6   0]\n",
      " [  0  34  44 131 779   0   4   0   8   0]\n",
      " [  0   0   1   1   0 278   3 660   5  52]\n",
      " [117  34 112 200 435   0  40   0  62   0]\n",
      " [  0   0   0   0   0   3   0 988   0   9]\n",
      " [  0   2  19  85 149   3  27   4 710   1]\n",
      " [  0   0   1   1   0  16   3 304   8 667]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyze_model(naive_bayes, x_test_prep_1d, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, estimator=RandomForestClassifier(n_estimators=1), n_jobs=1,\n",
       "             param_grid={'max_depth': [3, 3, 3, 3],\n",
       "                         'max_features': ['auto', 'log2', 0.15, None]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=1)\n",
    "rf_param_grid = {'max_depth': [3, 3, 3, 3], \n",
    "                 'max_features': ['auto', 'log2', 0.15, None]}\n",
    "rf_gridsearch = GridSearchCV(cv=4, estimator=random_forest, param_grid=rf_param_grid, scoring='accuracy', n_jobs=1)\n",
    "rf_gridsearch.fit(x_train_prep_1d, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3, 'max_features': 0.15}\n",
      "0.5175333333333333\n"
     ]
    }
   ],
   "source": [
    "print(rf_gridsearch.best_params_)\n",
    "print(rf_gridsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1000\n",
      "           1       0.96      0.78      0.86      1000\n",
      "           2       0.28      0.93      0.43      1000\n",
      "           3       0.34      0.89      0.50      1000\n",
      "           4       0.00      0.00      0.00      1000\n",
      "           5       0.81      0.18      0.29      1000\n",
      "           6       0.00      0.00      0.00      1000\n",
      "           7       0.51      0.88      0.64      1000\n",
      "           8       0.76      0.22      0.34      1000\n",
      "           9       0.80      0.80      0.80      1000\n",
      "\n",
      "    accuracy                           0.47     10000\n",
      "   macro avg       0.45      0.47      0.39     10000\n",
      "weighted avg       0.45      0.47      0.39     10000\n",
      "\n",
      "Confusion matrix:\n",
      "[[  0   8  89 880   0   2   0   8   3  10]\n",
      " [  0 784  11 191   0   7   0   5   2   0]\n",
      " [  0   5 932  38   0   3   0   7   9   6]\n",
      " [  0   7  76 893   0   0   0  12  12   0]\n",
      " [  0   5 857 130   0   1   0   5   1   1]\n",
      " [  0   1  32  31   0 176   0 666  20  74]\n",
      " [  0   4 634 349   0   4   0   8   0   1]\n",
      " [  0   0  12   1   0   7   0 879   2  99]\n",
      " [  0   3 666  61   0   8   0  30 217  15]\n",
      " [  0   0  18  33   0   9   0 117  19 804]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97252\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "analyze_model(rf_gridsearch, x_test_prep_1d, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n",
      "Fitting ExtraTreesClassifier on faces data with 1 cores...\n",
      "done in 6.694s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "#from sklearn.datasets import fetch_olivetti_faces\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    " \n",
    "# Number of cores to use to perform parallel fitting of the forest model\n",
    "n_jobs = 1\n",
    " \n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "# Load the faces dataset\n",
    "data = fashion_mnist\n",
    "X = train_images.reshape((len(train_images), -1))\n",
    "y = train_labels\n",
    " \n",
    "mask = y < 5  # Limit to 5 classes\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    " \n",
    "# Build a forest and compute the pixel importances\n",
    "print(\"Fitting ExtraTreesClassifier on faces data with %d cores...\" % n_jobs)\n",
    "t0 = time()\n",
    "forest = ExtraTreesClassifier(n_estimators=50,\n",
    "                              max_features=20,\n",
    "                              n_jobs=n_jobs,\n",
    "                              random_state=0)\n",
    " \n",
    "forest.fit(X, y)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "importances = forest.feature_importances_\n",
    "importances = importances.reshape(train_images[0].shape)\n",
    " \n",
    "# Plot pixel importances\n",
    "plt.matshow(importances, cmap=plt.cm.hot)\n",
    "plt.title(\"Pixel importances with forests of trees\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
