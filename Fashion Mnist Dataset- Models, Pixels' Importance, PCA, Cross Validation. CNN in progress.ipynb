{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      2       0       0       0       0       0       0       0       0   \n",
       "1      9       0       0       0       0       0       0       0       0   \n",
       "2      6       0       0       0       0       0       0       0       5   \n",
       "3      0       0       0       0       1       2       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0        30        43         0   \n",
       "3       0  ...         3         0         0         0         0         1   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imports for a Fashion Mnist predictor model\n",
    "\n",
    "import pandas as pd\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "pca= PCA(n_components=0.95)\n",
    "\n",
    "#reading the traiining dataset\n",
    "data=pd.read_csv(r'C:\\Users\\97252\\OneDrive\\שולחן העבודה\\הדנת- עבודת גמר\\Fashion Mnist dataset\\fashion-mnist_train.csv')\n",
    "\n",
    "X = data.drop(\"label\",axis = 1)\n",
    "y = data.label\n",
    "\n",
    "#shows the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 187)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PERFORMING PCA ON THE TRAINING DATA since it's very big\n",
    "\n",
    "pcadX = pca.fit_transform(X)\n",
    "\n",
    "# splitting the data into training and testing sets, with the pcad data(features)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(pcadX, y, test_size=0.2, random_state=0)\n",
    "\n",
    "pcadX.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The Classifier is \n",
      " RandomForestClassifier()\n",
      "\n",
      " The Model's Score is 0.876\n",
      "[[2514    1   36  104   17    2  237    0   33    0]\n",
      " [   7 2932   17   56    8    0   21    0    2    0]\n",
      " [  15    0 2452   22  338    0  146    0   18    0]\n",
      " [  66    6   18 2783   82    0   76    0    8    1]\n",
      " [   8    3  236  139 2438    1  108    0    7    0]\n",
      " [   0    0    0    1    0 2860    0   86   11   20]\n",
      " [ 507    3  352   79  301    2 1746    0   50    0]\n",
      " [   0    0    0    0    0   60    0 2791    4  126]\n",
      " [   3    0   17   11   17    8   39    8 2909    3]\n",
      " [   0    0    1    1    0   39    2  124    2 2859]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83      2944\n",
      "           1       1.00      0.96      0.98      3043\n",
      "           2       0.78      0.82      0.80      2991\n",
      "           3       0.87      0.92      0.89      3040\n",
      "           4       0.76      0.83      0.79      2940\n",
      "           5       0.96      0.96      0.96      2978\n",
      "           6       0.74      0.57      0.64      3040\n",
      "           7       0.93      0.94      0.93      2981\n",
      "           8       0.96      0.96      0.96      3015\n",
      "           9       0.95      0.94      0.95      3028\n",
      "\n",
      "    accuracy                           0.88     30000\n",
      "   macro avg       0.87      0.88      0.87     30000\n",
      "weighted avg       0.88      0.88      0.87     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#training and predicting on the PCA-d data using-\n",
    "#K-Neighbors\n",
    "#Decision Tree\n",
    "#Random Forest\n",
    "#AdaBoost\n",
    "#Gradient Boosting\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "classifiers = [\n",
    "    RandomForestClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    KNeighborsClassifier(3),\n",
    "    DecisionTreeClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    ]\n",
    "\n",
    "\n",
    "for classifier in classifiers:\n",
    "    model = classifier.fit(X_train, y_train)\n",
    "    print(\"\\n The Classifier is \\n \" +str(classifier))\n",
    "    print(\"\\n The Model's Score is %.3f\" % model.score(X_test, y_test))\n",
    "    y_pred_best = model.predict(X_test)\n",
    "    cm=confusion_matrix(y_test, y_pred_best, labels=None, sample_weight=None)\n",
    "    print(cm)\n",
    "    print(classification_report(y_test,y_pred_best))\n",
    "    #cross validation- only for KNN classifier (time reasons)\n",
    "    if (str(classifier) == 'KNeighborsClassifier(n_neighbors=5)'):  #CROSS VALIDATION! activate only KNN\n",
    "        score= cross_val_score(classifier, Xa_test, ya_test, cv=4)\n",
    "        print(\"This model's Score with cross validation is \", score)\n",
    "        \n",
    "    #sns.heatmap(pd.DataFrame(classification_report).iloc[:-1, :].T, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#PLOTTING PIXELS IMPORATNCE! BY RANDOM FORESTS\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\n",
    "model.fit(X, y) #on the ORIGINAL dataset (features: X! so we won't lose features according to the PCA procedure)\n",
    "\n",
    "importances = model.feature_importances_\n",
    "pixels = np.reshape(importances,(28,28)) #since the shape of the dataset is (60000,728)\n",
    "\n",
    "plt.figure(figsize= (10,8))\n",
    "plot = sns.heatmap(pixels,cmap=plt.cm.hot)\n",
    "plt.xticks([], [])\n",
    "plot.set_yticks([])\n",
    "plot.set_yticks([], minor=True)\n",
    "colorbar = plot.collections[0].colorbar\n",
    "colorbar.set_ticks([0,max(importances)])\n",
    "colorbar.set_ticklabels(['not important','Very important'])\n",
    "plt.title('Pixels Importance',size = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest classifier on the ORIGINAL data results in:\n",
      "\n",
      " The Model's Score is 0.761\n",
      "[[2316   21  127  370   17    2    7    0   84    0]\n",
      " [   5 2652   60  316    5    2    0    0    3    0]\n",
      " [  30    1 2127   34  748    2    6    0   43    0]\n",
      " [  88   19  112 2714   82    1   11    0   13    0]\n",
      " [   8    9  360  387 2150    2    3    0   21    0]\n",
      " [   1    1    0    5    0 2531    0  263   39  138]\n",
      " [ 700    6  610  288 1224    4   85    0  123    0]\n",
      " [   0    0    0    0    0   45    0 2676    4  256]\n",
      " [  13    4  105   61   14   31    5   12 2767    3]\n",
      " [   1    0    0    3    0   24    0  171    8 2821]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76      2944\n",
      "           1       0.98      0.87      0.92      3043\n",
      "           2       0.61      0.71      0.66      2991\n",
      "           3       0.65      0.89      0.75      3040\n",
      "           4       0.51      0.73      0.60      2940\n",
      "           5       0.96      0.85      0.90      2978\n",
      "           6       0.73      0.03      0.05      3040\n",
      "           7       0.86      0.90      0.88      2981\n",
      "           8       0.89      0.92      0.90      3015\n",
      "           9       0.88      0.93      0.90      3028\n",
      "\n",
      "    accuracy                           0.76     30000\n",
      "   macro avg       0.78      0.76      0.73     30000\n",
      "weighted avg       0.78      0.76      0.73     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#fun fact! this is the second time Random Forest is used. the first time on the PCA-d data, and now on the ORIGINAL one.\n",
    "\n",
    "#Let's compare the model's results according to the datas!\n",
    "\n",
    "print('Random Forest classifier on the ORIGINAL data results in:')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "print(\"\\n The Model's Score is %.3f\" % model.score(X_test, y_test))\n",
    "\n",
    "y_pred_best = model.predict(X_test)\n",
    "cm=confusion_matrix(y_test, y_pred_best, labels=None, sample_weight=None)\n",
    "print(cm)\n",
    "print(classification_report(y_test,y_pred_best))\n",
    "\n",
    "#seeing this, the model works better on the PCA-d data. since it has less features.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "\n",
    "#predicting by Logistic Regression on the ORIGINAL dataset\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "#Creating and training the model\n",
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(X_train, y_train)\n",
    "predictions = logmodel.predict(X_test)\n",
    "\n",
    "#Evaluating the model\n",
    "cfm = metrics.confusion_matrix(y_test, predictions)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "\n",
    "#Naive Bayes algorithm\n",
    "\n",
    "naive_bayes = GaussianNB()\n",
    "print(np.mean(cross_val_score(estimator=naive_bayes, cv=4, scoring='accuracy', X=x_train_prep_1d, y=y_train)))\n",
    "naive_bayes.fit(x_train_prep_1d, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 784)\n",
      "(30000,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_42_input to have shape (36,) but got array with shape (784,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-f10a99de4307>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m# build the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;31m#Predict on the Test Data and Compute Evaluation Metrics;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    143\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    146\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected dense_42_input to have shape (36,) but got array with shape (784,)"
     ]
    }
   ],
   "source": [
    "#CNN- NEURAL NETWORK predictor\n",
    "\n",
    "#Define, Compile, and Fit the Keras Classification Model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(500, activation='relu', input_dim=36))  #the input layer which specifies the activation function and the number of input dimensions, which in our case is 36 predictors.\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax')) #The fifth line of code creates the output layer with four nodes because there are four output classes\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "# normalize to range 0-1\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "\n",
    "# build the model\n",
    "model.fit(X_train, y_train, epochs=1)\n",
    "\n",
    "#Predict on the Test Data and Compute Evaluation Metrics;\n",
    "\n",
    "#pred_train= model.predict(X_train)\n",
    "#scores2 = model.evaluate(X_train, y_train, verbose=0)\n",
    "#print('Accuracy on train data: {}% \\n Error on train data: {}'.format(scores2[1], 1 - scores2[1]))    \n",
    "\n",
    "print('')\n",
    "\n",
    "pred_test= model.predict(X_test)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Accuracy on test data: {}% \\n Error on test data: {}'.format(scores[1], 1 - scores[1]))   \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
